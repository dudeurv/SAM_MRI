{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOq1miQeCHzNio29OOxYedb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dudeurv/SAM_MRI/blob/main/choose_best_epoch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYws8D9Ea_mn"
      },
      "outputs": [],
      "source": [
        "def test_per_epoch(model, testloader, ce_loss, dice_loss, multimask_output=True, args=None):\n",
        "    model.eval()\n",
        "    loss_per_epoch = []\n",
        "    num_classes = args.num_classes + 1\n",
        "    confusion_matrix = np.zeros((num_classes, num_classes), dtype=np.uint32)\n",
        "    with torch.no_grad():\n",
        "        for i_batch, sampled_batch in enumerate(testloader):\n",
        "            image_batch, label_batch, low_res_label_batch = sampled_batch['image'],sampled_batch['label'], sampled_batch['low_res_label']\n",
        "            image_batch, label_batch, low_res_label_batch = image_batch.to(device, dtype=torch.float32), label_batch.to(device, dtype=torch.long), low_res_label_batch.to(device, dtype=torch.long)\n",
        "\n",
        "            outputs = model(image_batch, multimask_output, args.img_size)\n",
        "\n",
        "            logits = outputs['masks']\n",
        "            prob = F.softmax(logits, dim=1)\n",
        "            pred_seg = torch.argmax(prob, dim=1)\n",
        "            confusion_matrix += calculate_confusion_matrix_from_arrays(pred_seg.cpu(), label_batch.cpu(), num_classes)\n",
        "\n",
        "            loss, loss_ce, loss_dice = calc_loss(outputs, low_res_label_batch, ce_loss, dice_loss)\n",
        "            loss_per_epoch.append(loss.item())\n",
        "\n",
        "        confusion_matrix = confusion_matrix[1:, 1:]  # exclude background\n",
        "        dices_per_class = {'dice_cls:{}'.format(cls + 1): dice\n",
        "                    for cls, dice in enumerate(calculate_dice(confusion_matrix))}\n",
        "\n",
        "    return np.mean(loss_per_epoch), dices_per_class"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_epoch, best_dice = 0.0, 0.0\n",
        "for epoch in range(args.max_epochs):\n",
        "    loss_training = training_per_epoch(net, trainloader, optimizer, iter_num, ce_loss, dice_loss, multimask_output=multimask_output, args=args)\n",
        "    loss_testing, dice = test_per_epoch(net, testloader, ce_loss, dice_loss,multimask_output=True, args=args)\n",
        "    loss_testing, dice_public = test_per_epoch(net, testloader, ce_loss, dice_loss,multimask_output=True, args=args)\n",
        "\n",
        "    dice_public_class1 = dice_public['dice_cls:1']\n",
        "    dice_class1 = dice['dice_cls:1']\n",
        "\n",
        "    # Average the two class 1 dice scores\n",
        "    average_dice_class1 = (dice_public_class1 + dice_class1) / 2\n",
        "\n",
        "    # Combine class 1 average with other class dice scores\n",
        "    dice_values = np.array([average_dice_class1] + [dice['dice_cls:2']])\n",
        "\n",
        "    total_dice = np.mean(dice_values)"
      ],
      "metadata": {
        "id": "9AFKx0IMbIvm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}