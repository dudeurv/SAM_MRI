# -*- coding: utf-8 -*-
"""trainer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1glvKPrJJ5iuKvcUdEyWDfPk6mLVRFGEM
"""

pip install tensorboardX

# Import necessary libraries
import os
import random
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from glob import glob
import imageio.v2 as iio
from tqdm import tqdm
from tensorboardX import SummaryWriter

# Define the function to normalize image intensity
def normalise_intensity(image, ROI_thres=0.1):
    pixel_thres = np.percentile(image, ROI_thres)
    ROI = np.where(image > pixel_thres, image, 0)
    mean = np.mean(ROI)
    std = np.std(ROI)
    ROI_norm = (ROI - mean) / (std + 1e-8)
    return ROI_norm

# Function to map labels
def map_labels(label):
    label_map = {0: 0, 85: 1, 170: 2, 255: 3}
    mapped_label = label.copy()
    for k, v in label_map.items():
        mapped_label[label == k] = v
    return mapped_label

# Define a custom dataset class for the Brats dataset
class BratsDataset(Dataset):
    def __init__(self, root):
        self.img_path_all = glob(root + '/BraTS-GLI-t1c/*.png')
        self.mask_path_all = [img_path.replace('t1c', 'seg') for img_path in self.img_path_all]

    def __len__(self):
        return len(self.img_path_all)

    def __getitem__(self, index):
        image = iio.imread(self.img_path_all[index])
        image = normalise_intensity(image)
        label = iio.imread(self.mask_path_all[index])
        label = map_labels(label)
        return image, label

# Define the training function for a single epoch
def train_per_epoch(model, trainloader, loss_fn, optimizer, device):
    model.train()
    loss_per_epoch = []
    for batch_idx, (images, labels) in enumerate(trainloader):
        images, labels = images.unsqueeze(1).to(device, dtype=torch.float32), labels.to(device, dtype=torch.long)
        logits = model(images)
        optimizer.zero_grad()
        loss = loss_fn(logits, labels)
        loss.backward()
        optimizer.step()
        loss_per_epoch.append(loss.item())
    return np.mean(loss_per_epoch)

# Define the testing function for a single epoch
def test_per_epoch(model, testloader, loss_fn, device):
    model.eval()
    loss_per_epoch = []
    with torch.no_grad():
        for batch_idx, (images, labels) in enumerate(testloader):
            images, labels = images.unsqueeze(1).to(device, dtype=torch.float32), labels.to(device, dtype=torch.long)
            logits = model(images)
            loss = loss_fn(logits, labels)
            loss_per_epoch.append(loss.item())
    return np.mean(loss_per_epoch)

# The main training function
def trainer_synapse(args, model, snapshot_path):
    logging.basicConfig(filename=snapshot_path + "/log.txt", level=logging.INFO, format='[%(asctime)s.%(msecs)03d] %(message)s', datefmt='%H:%M:%S')
    logging.getLogger().addHandler(logging.StreamHandler(sys.stdout))
    logging.info(str(args))

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model.to(device)

    base_lr = args.base_lr
    batch_size = args.batch_size
    max_epochs = args.max_epochs
    stop_epoch = args.stop_epoch

    train_dataset = BratsDataset(root='/content/samed_codes/Slices/Train')
    test_dataset = BratsDataset(root='/content/samed_codes/Slices/Test')
    trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

    ce_loss = nn.CrossEntropyLoss()
    optimizer = optim.AdamW(model.parameters(), lr=base_lr)

    writer = SummaryWriter(snapshot_path + '/log')

    for epoch_num in tqdm(range(max_epochs), ncols=70):
        train_loss = train_per_epoch(model, trainloader, ce_loss, optimizer, device)
        test_loss = test_per_epoch(model, testloader, ce_loss, device)

        writer.add_scalar('train/loss', train_loss, epoch_num)
        writer.add_scalar('test/loss', test_loss, epoch_num)
        logging.info(f'Epoch {epoch_num} - Train Loss: {train_loss}, Test Loss: {test_loss}')

        if epoch_num % 20 == 0 or epoch_num >= max_epochs - 1 or epoch_num >= stop_epoch - 1:
            save_mode_path = os.path.join(snapshot_path, f'epoch_{epoch_num}.pth')
            torch.save(model.state_dict(), save_mode_path)
            logging.info(f"Saved model to {save_mode_path}")

    writer.close()
    return "Training Finished!"