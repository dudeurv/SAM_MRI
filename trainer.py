# -*- coding: utf-8 -*-
"""trainer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1glvKPrJJ5iuKvcUdEyWDfPk6mLVRFGEM
"""

!pip install tensorboardX

# Import libraries
import tarfile
import re
import imageio.v2 as iio
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset
import numpy as np
import time
import os
import random
import matplotlib.pyplot as plt
from matplotlib import colors
import scipy.ndimage
import textwrap

!gdown https://drive.google.com/uc?id=1nHZWlCBpudbT4zzPyqyu2Vi5uILcxSrv

# Assuming the downloaded file is a ZIP file and its name is 'downloaded_data.zip'
import zipfile
with zipfile.ZipFile('Slices.zip', 'r') as zip_ref:
    zip_ref.extractall()

# Import necessary libraries
from torch.utils.data import Dataset, DataLoader  # PyTorch classes for handling datasets and data loading
from glob import glob                            # For file path pattern matching
import imageio.v2 as iio
import matplotlib.pyplot as plt
import numpy as np

def normalise_intensity(image, ROI_thres=0.1):
    pixel_thres = np.percentile(image, ROI_thres)
    ROI = np.where(image > pixel_thres, image, 0) # If image value is greater than pixel threshold, return image value, otherwise return 0
    mean = np.mean(ROI)
    std = np.std(ROI)
    ROI_norm = (ROI - mean) / (std + 1e-8) # Normalise ROI
    return ROI_norm

def map_labels(label):
    label_map = {0: 0, 85: 1, 170: 2, 255: 3}
    mapped_label = label.copy()
    for k, v in label_map.items():
        mapped_label[label == k] = v
    return mapped_label

# Define a custom dataset class for the Brats dataset
class BratsDataset(Dataset):
    # Initialization method of the class
    def __init__(self, root='brats_train'):
        # Get all image file paths using glob
        self.img_path_all = glob(root + '/BraTS-GLI-t1c/*.png')
        # Get the corresponding mask file paths by replacing 't1c' with 'seg' in the image paths
        self.mask_path_all = [img_path.replace('t1c', 'seg') for img_path in self.img_path_all]

    # Method to return the length of the dataset
    def __len__(self):
        return len(self.img_path_all)

    # Method to get an item from the dataset
    def __getitem__(self, index):
        # Read the image at the given index
        image = iio.imread(self.img_path_all[index])
        # Normalize the intensity of the image
        image = normalise_intensity(image)
        # Read the label (mask) corresponding to the image
        label = iio.imread(self.mask_path_all[index])
        # Map the label values to class indices
        label = map_labels(label)
        return image, label

# Create instances of the dataset for training and testing
train_dataset = BratsDataset(root='Slices/Train')
test_dataset = BratsDataset(root='Slices/Test')

!gdown https://drive.google.com/uc?id=1nHZWlCBpudbT4zzPyqyu2Vi5uILcxSrv

# Assuming the downloaded file is a ZIP file and its name is 'downloaded_data.zip'
import zipfile
with zipfile.ZipFile('Slices.zip', 'r') as zip_ref:
    zip_ref.extractall()

# Import necessary libraries
from torch.utils.data import Dataset, DataLoader  # PyTorch classes for handling datasets and data loading
from glob import glob                            # For file path pattern matching
import imageio.v2 as iio
import matplotlib.pyplot as plt
import numpy as np

def normalise_intensity(image, ROI_thres=0.1):
    pixel_thres = np.percentile(image, ROI_thres)
    ROI = np.where(image > pixel_thres, image, 0) # If image value is greater than pixel threshold, return image value, otherwise return 0
    mean = np.mean(ROI)
    std = np.std(ROI)
    ROI_norm = (ROI - mean) / (std + 1e-8) # Normalise ROI
    return ROI_norm

def map_labels(label):
    label_map = {0: 0, 85: 1, 170: 2, 255: 3}
    mapped_label = label.copy()
    for k, v in label_map.items():
        mapped_label[label == k] = v
    return mapped_label

# Define a custom dataset class for the Brats dataset
class BratsDataset(Dataset):
    # Initialization method of the class
    def __init__(self, root='brats_train'):
        # Get all image file paths using glob
        self.img_path_all = glob(root + '/BraTS-GLI-t1c/*.png')
        # Get the corresponding mask file paths by replacing 't1c' with 'seg' in the image paths
        self.mask_path_all = [img_path.replace('t1c', 'seg') for img_path in self.img_path_all]

    # Method to return the length of the dataset
    def __len__(self):
        return len(self.img_path_all)

    # Method to get an item from the dataset
    def __getitem__(self, index):
        # Read the image at the given index
        image = iio.imread(self.img_path_all[index])
        # Normalize the intensity of the image
        image = normalise_intensity(image)
        # Read the label (mask) corresponding to the image
        label = iio.imread(self.mask_path_all[index])
        # Map the label values to class indices
        label = map_labels(label)
        return image, label

# Create instances of the dataset for training and testing
train_dataset = BratsDataset(root='Slices/Train')
test_dataset = BratsDataset(root='Slices/Test')

# Import necessary libraries for the deep learning model
import torch
import torch.optim as optim
import torch.nn as nn
from torch.utils.data import DataLoader

# Define the training function for a single epoch
def train_per_epoch(model, trainloader, loss_fn, optimizer):
    model.train()  # Set the model to training mode (affects layers like dropout, batchnorm, etc.)
    loss_per_epoch = []  # Initialize a list to store loss values for each batch

    # Loop over each batch in the training loader
    for batch_idx, (images, labels) in enumerate(trainloader):
        # Move the images and labels to the defined device (GPU/CPU) and set appropriate data types
        images, labels = images.unsqueeze(1).to(device, dtype=torch.float32), labels.to(device, dtype=torch.long)

        # Forward pass: compute the predicted labels by passing images to the model
        logits = model(images)

        optimizer.zero_grad()  # Zero out any existing gradients in the optimizer
        loss = loss_fn(logits, labels)  # Compute the loss between predictions and true labels
        loss.backward()  # Perform backpropagation to calculate gradients
        optimizer.step()  # Update the model parameters based on the gradients
        loss_per_epoch.append(loss.item())  # Append the current batch loss to the list

    # Calculate and return the average loss for the epoch
    return torch.tensor(loss_per_epoch).mean().item()

# Define the testing function for a single epoch
def test_per_epoch(model, testloader, loss_fn, optimizer):
    model.eval()  # Set the model to evaluation mode
    loss_per_epoch = []  # Initialize a list to store loss values for each batch

    # Disable gradient calculations for efficiency during testing
    with torch.no_grad():
        # Loop over each batch in the testing loader
        for batch_idx, (images, labels) in enumerate(testloader):
            # Move the images and labels to the defined device and set appropriate data types
            images, labels = images.unsqueeze(1).to(device, dtype=torch.float32), labels.to(device, dtype=torch.long)

            # Forward pass: compute the predicted labels by passing images to the model
            logits = model(images)

            # Compute the loss and append to the list
            loss = loss_fn(logits, labels)
            loss_per_epoch.append(loss.item())

    # Calculate and return the average loss for the epoch
    return torch.tensor(loss_per_epoch).mean().item()

import logging
import os
import random
import sys
from tqdm import tqdm
from tensorboardX import SummaryWriter
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader

# Assume BratsDataset, train_per_epoch, and test_per_epoch are defined as in your script

def trainer_synapse(args, model, snapshot_path):
    # Configure logging
    logging.basicConfig(filename=snapshot_path + "/log.txt", level=logging.INFO,
                        format='[%(asctime)s.%(msecs)03d] %(message)s', datefmt='%H:%M:%S')
    logging.getLogger().addHandler(logging.StreamHandler(sys.stdout))
    logging.info(str(args))

    # Configure training parameters
    base_lr = args.base_lr
    batch_size = args.batch_size
    max_epochs = args.max_epochs
    stop_epoch = args.stop_epoch

    # Initialize datasets and dataloaders
    train_dataset = BratsDataset(root='Slices/Train')
    test_dataset = BratsDataset(root='Slices/Test')
    trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    testloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

    # Prepare model for training
    model.train()
    if args.n_gpu > 1:
        model = nn.DataParallel(model)

    # Loss function and optimizer
    ce_loss = nn.CrossEntropyLoss()
    optimizer = optim.AdamW(model.parameters(), lr=base_lr)

    # Tensorboard writer for logging
    writer = SummaryWriter(snapshot_path + '/log')

    # Training loop
    for epoch_num in tqdm(range(max_epochs), ncols=70):
        # Training for one epoch
        train_loss = train_per_epoch(model, trainloader, ce_loss, optimizer)
        # Testing for one epoch
        test_loss = test_per_epoch(model, testloader, ce_loss, optimizer)

        # Logging
        writer.add_scalar('train/loss', train_loss, epoch_num)
        writer.add_scalar('test/loss', test_loss, epoch_num)
        logging.info(f'Epoch {epoch_num} - Train Loss: {train_loss}, Test Loss: {test_loss}')

        # Save model checkpoint
        if epoch_num % 20 == 0 or epoch_num >= max_epochs - 1 or epoch_num >= stop_epoch - 1:
            save_mode_path = os.path.join(snapshot_path, f'epoch_{epoch_num}.pth')
            torch.save(model.state_dict(), save_mode_path)
            logging.info(f"Saved model to {save_mode_path}")

    # Close Tensorboard writer
    writer.close()
    return "Training Finished!"